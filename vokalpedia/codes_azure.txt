fichier text_to_speech azure
import azure.cognitiveservices.speech as speechsdk
import datetime


speech_key="43958a24ba0d40c4943955c1fb3a4014"
service_region="francecentral"

def speech_synthesis_with_auto_language_detection_to_speaker(text,search):
    """performs speech synthesis to the default speaker with auto language detection
       Note: this is a preview feature, which might be updated in future versions."""

    now = datetime.datetime.today()
    timestamp = datetime.datetime.timestamp(now)

    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)

    # create the auto detection language configuration without specific languages
    auto_detect_source_language_config = speechsdk.languageconfig.AutoDetectSourceLanguageConfig()

    # Creates a speech synthesizer using the default speaker as audio output.
    speech_synthesizer = speechsdk.SpeechSynthesizer(
        speech_config=speech_config, auto_detect_source_language_config=auto_detect_source_language_config,audio_config=None)

    result = speech_synthesizer.speak_text_async(text).get()
        # Check result
    if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
            print("Speech synthesized to speaker for text [{}]".format(text))
            stream = speechsdk.AudioDataStream(result)
            stream.save_to_wav_file(f"{search}_{timestamp}.wav")





Fichier image_captioning:
import json
import http.client, urllib.request, urllib.parse, urllib.error, base64
from translate import Translator

def image_captiong_azure(url):
    # Fonction réalisant un appel API au modèle de description d'images de Microsoft Azure

    headers = {'Content-Type': 'application/json',
    'Ocp-Apim-Subscription-Key': 'f5aae19eb1024e39a4ed30ed514779d9'}

    body=json.dumps({"url": url})

    params = urllib.parse.urlencode({
            'maxCandidates': '1',
            'language': 'en',
        'model-version': 'latest',
        })

    params += '&VisualFeatures=description'

    try:
        conn = http.client.HTTPSConnection('francecentral.api.cognitive.microsoft.com')
        conn.request("POST", "/vision/v3.2/analyze?%s" % params, body, headers)
        response = conn.getresponse()
        data = response.read()
        print(data)
        conn.close()
    except Exception as e:
        print("[Errno {0}] {1}".format(e.errno, e.strerror))


    data = json.loads(data)

    res = data['description']['captions'][0]['text']

    translator= Translator(to_lang="fr")
    translation = translator.translate(res)

    return translation
